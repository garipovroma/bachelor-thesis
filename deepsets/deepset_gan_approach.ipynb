{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0d7542e-84fb-4984-986e-ecaef13eae9e",
      "metadata": {
        "id": "f0d7542e-84fb-4984-986e-ecaef13eae9e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4POpkGODNNZ9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4POpkGODNNZ9",
        "outputId": "94c5cb3b-09b9-449b-eaac-eb726eab8d26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UGzH3WgGNVWQ",
      "metadata": {
        "id": "UGzH3WgGNVWQ"
      },
      "outputs": [],
      "source": [
        "!cp -r drive/MyDrive/diploma/deepset/* ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "K0PDhuQrDqNX",
      "metadata": {
        "id": "K0PDhuQrDqNX"
      },
      "outputs": [],
      "source": [
        "!cp drive/MyDrive/diploma/deepset/train_meta_tensors.npy ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dWatByViDvCJ",
      "metadata": {
        "id": "dWatByViDvCJ"
      },
      "outputs": [],
      "source": [
        "!cp drive/MyDrive/diploma/deepset/test_meta_tensors.npy ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rxJHfv4JQCmi",
      "metadata": {
        "id": "rxJHfv4JQCmi"
      },
      "outputs": [],
      "source": [
        "!unzip processed_data.zip   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XN_SAgqV6iS5",
      "metadata": {
        "id": "XN_SAgqV6iS5"
      },
      "outputs": [],
      "source": [
        "class CONFIG:\n",
        "    # DATA\n",
        "    features = 16\n",
        "    instances = 64\n",
        "    classes = 2\n",
        "    z_length = 128\n",
        "\n",
        "    # TRAIN\n",
        "    num_epochs = 20\n",
        "    train_batch_size = 1024\n",
        "    learning_rate = 0.002\n",
        "    criterion = 'torch.nn.BCEWithLogitsLoss'\n",
        "\n",
        "    test_batch_size = 1024\n",
        "\n",
        "    # MODEL\n",
        "    hidden_size_0=128\n",
        "    hidden_size_1=256\n",
        "    predlast_hidden_size=512\n",
        "    meta_size=27\n",
        "    out_classes=4\n",
        "    standardscaler=True\n",
        "    meta_standardscaler=True\n",
        "    transpose=True\n",
        "\n",
        "    # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else if torch.backends.mps.is_available() then \"mps\" else \"cpu\")\n",
        "    # device is cuda is available else mps is available else cpu\n",
        "    device_mps_or_cpu = (\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else device_mps_or_cpu)\n",
        "\n",
        "    # OTHER\n",
        "    seed = 42\n",
        "    num_workers = 8\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Of2YdfSFNKFr",
      "metadata": {
        "id": "Of2YdfSFNKFr"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "APtjj-ITzO72",
      "metadata": {
        "id": "APtjj-ITzO72"
      },
      "source": [
        "### Discriminator = model v4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZrcuD4zTzOqK",
      "metadata": {
        "id": "ZrcuD4zTzOqK"
      },
      "outputs": [],
      "source": [
        "from deepsets import deepsetlayers\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Discriminator(torch.nn.Module):\n",
        "    '''\n",
        "    DeepSetModelV3 discriminator\n",
        "    '''\n",
        "    def __init__(self, hidden_size_0=1, hidden_size_1=1, predlast_hidden_size=1, meta_size = 27, out_classes=1):\n",
        "        super().__init__()\n",
        "        self.hidden_size_0 = hidden_size_0\n",
        "        self.hidden_size_1 = hidden_size_1\n",
        "        self.predlast_hidden_size = predlast_hidden_size\n",
        "        self.meta_size = meta_size\n",
        "        self.out_classes = out_classes\n",
        "        self.inv_0 = deepsetlayers.InvLinear(hidden_size_0, hidden_size_0)\n",
        "        self.inv_1 = deepsetlayers.InvLinear(2 * hidden_size_1, 4 * hidden_size_1)\n",
        "        self.equiv_0 = deepsetlayers.EquivLinear(1, hidden_size_0)\n",
        "        self.equiv_1 = deepsetlayers.EquivLinear(hidden_size_0, 2 * hidden_size_1)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.regressor = torch.nn.Sequential(\n",
        "            torch.nn.Linear(4 * hidden_size_1 + meta_size, 2 * predlast_hidden_size),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(2 * predlast_hidden_size, predlast_hidden_size),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(predlast_hidden_size, out_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        x = x.unsqueeze(-1)\n",
        "        # (batch_size, N, M, 1)\n",
        "        N = x.shape[1]\n",
        "        x = x.flatten(0, 1)\n",
        "        # (batch_size * N, M, 1)\n",
        "        x = self.equiv_0(x)\n",
        "        # (batch_size * N, M, hidden_size_0)\n",
        "        x = self.relu(x)\n",
        "        x = self.inv_0(x)\n",
        "        # (batch_size * N, hidden_size_0)\n",
        "        x = x.reshape(-1, N, self.hidden_size_0)\n",
        "        # (batch_size, N, hidden_size_0)\n",
        "\n",
        "        x = self.equiv_1(x)\n",
        "        # (batch_size, N, hidden_size_1)\n",
        "        x = self.relu(x)\n",
        "        x = self.inv_1(x)\n",
        "        # (batch_size, hidden_size_1)\n",
        "\n",
        "        y = y.view(-1, self.meta_size)\n",
        "        # (batch_size, meta_size)        \n",
        "\n",
        "        x = torch.hstack([x, y])\n",
        "        # (batch_size, hidden_size_1 + meta_size)\n",
        "        x = self.regressor(x)\n",
        "        # (batch_size, out_classes)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ul0ane-PCh3i",
      "metadata": {
        "id": "ul0ane-PCh3i"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "cV1JSJJZ8HUx",
      "metadata": {
        "id": "cV1JSJJZ8HUx"
      },
      "source": [
        "### Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_6-b95cPCjSd",
      "metadata": {
        "id": "_6-b95cPCjSd"
      },
      "outputs": [],
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lyPcsib78Gm2",
      "metadata": {
        "id": "lyPcsib78Gm2"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class Generator(torch.nn.Module):\n",
        "    def __init__(self, features_size, instances_size, classes_size, meta_length, z_length):\n",
        "        super(Generator, self).__init__()\n",
        "        \n",
        "        # nz = # Size of z latent vector (i.e. size of generator input)\n",
        "        # ngf = # Size of feature maps in discriminator\n",
        "        # nc = # Number of channels in the training samples. For dataset this is 1,\n",
        "        # but for torch.cat([dataset, target_map], dim=2) this is 2\n",
        "        # self.nc = nc\n",
        "        # self.nz = nz\n",
        "        # self.nfg = nfg\n",
        "\n",
        "        self.features_size = features_size\n",
        "        self.instances_size = instances_size\n",
        "        self.data_size = instances_size\n",
        "        self.classes_size = classes_size\n",
        "        self.meta_length = meta_length\n",
        "        self.z_length = z_length\n",
        "\n",
        "\n",
        "        # self.fc_z = nn.ConvTranspose2d(in_channels=self.z_length,\n",
        "        #                                out_channels=self.data_size * 4, kernel_size=4, stride=1, padding=0)\n",
        "        # # in (?, meta_length, 1, 1)\n",
        "        # # out (?, data_size * 4, 4, 4)\n",
        "        # self.fc_meta = nn.ConvTranspose2d(in_channels=self.meta_length,\n",
        "        #                                   out_channels=self.data_size * 4, kernel_size=4, stride=1, padding=0)\n",
        "        # # in (?, data_size * 8, 4, 4)\n",
        "        # # out (?, data_size * 4, 8, 8)\n",
        "        # self.deconv1 = nn.ConvTranspose2d(in_channels=self.data_size * 8,\n",
        "        #                                   out_channels=self.data_size * 4, kernel_size=4, stride=2, padding=1)\n",
        "        # # out (?, data_size * 2, 16, 16)\n",
        "        # self.deconv2 = nn.ConvTranspose2d(in_channels=self.data_size * 4,\n",
        "        #                                   out_channels=self.data_size * 2, kernel_size=4, stride=2, padding=1)\n",
        "        # # out (?, data_size, 32, 16)\n",
        "        # self.deconv3 = nn.ConvTranspose2d(in_channels=self.data_size * 2,\n",
        "        #                                   out_channels=self.data_size, kernel_size=(4, 1), stride=(2, 1),\n",
        "        #                                   padding=(1, 0))\n",
        "        # # out (?, data_size / 2, 64, 16)\n",
        "        # self.deconv4 = nn.ConvTranspose2d(in_channels=self.data_size,\n",
        "        #                                   out_channels=classes_size, kernel_size=(4, 1), stride=(2, 1), padding=(1, 0))\n",
        "\n",
        "        self.upconv_z = nn.ConvTranspose2d(in_channels=self.z_length,\n",
        "                                       out_channels=self.data_size * 4, kernel_size=4, stride=1, padding=0)\n",
        "        self.upconv_meta = nn.ConvTranspose2d(in_channels=self.meta_length,\n",
        "                                          out_channels=self.data_size * 4, kernel_size=4, stride=1, padding=0)\n",
        "        \n",
        "        # after cat:\n",
        "        # (?, data_size * 8, 4, 4)\n",
        "\n",
        "        self.main_upconv = nn.Sequential(\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(in_channels=8 * self.data_size,\n",
        "                                out_channels=self.data_size * 4, kernel_size=4, \n",
        "                                stride=2, padding=1, bias=False),\n",
        "            # nn.BatchNorm(self.data_size * 8),\n",
        "            nn.ReLU(True),\n",
        "            ### ^ - (?, data_size * 8, 8, 8)\n",
        "            nn.ConvTranspose2d(in_channels=self.data_size * 4,\n",
        "                               out_channels=self.data_size * 2, kernel_size=4, \n",
        "                               stride=2, padding=1, bias=False),\n",
        "            # nn.BatchNorm(self.data_size * 4),\n",
        "            nn.ReLU(True),\n",
        "            ### ^ - (?, data_size * 4, 16, 16)\n",
        "            nn.ConvTranspose2d(in_channels=self.data_size * 2,\n",
        "                               out_channels=self.data_size, kernel_size=(4, 1), \n",
        "                               stride=(2, 1), padding=(1, 0)),\n",
        "            # nn.BatchNorm(self.data_size * 2),\n",
        "            nn.ReLU(True),\n",
        "            ### ^ - (?, data_size, 32, 16)\n",
        "            nn.ConvTranspose2d(in_channels=self.data_size,\n",
        "                                          out_channels=classes_size, kernel_size=(4, 1), stride=(2, 1), padding=(1, 0)),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z, meta):\n",
        "        upsampled_z = self.upconv_z(z)\n",
        "        upsampled_meta = self.upconv_meta(meta)\n",
        "\n",
        "        upsampled_conditional_vector = torch.cat((upsampled_z, upsampled_meta), 1)\n",
        "\n",
        "        result = self.main_upconv(upsampled_conditional_vector)\n",
        "        return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8KKumAacI0XQ",
      "metadata": {
        "id": "8KKumAacI0XQ"
      },
      "outputs": [],
      "source": [
        "d_model = Discriminator(hidden_size_0=CONFIG.hidden_size_0, \n",
        "                     hidden_size_1=CONFIG.hidden_size_1, \n",
        "                     predlast_hidden_size=CONFIG.predlast_hidden_size, \n",
        "                     meta_size=CONFIG.meta_size,\n",
        "                     out_classes=CONFIG.out_classes)\n",
        "\n",
        "g_model = Generator(CONFIG.features,\n",
        "                    CONFIG.instances,\n",
        "                    CONFIG.classes,\n",
        "                    CONFIG.meta_size,\n",
        "                    CONFIG.z_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RHVR8n4CNRCs",
      "metadata": {
        "id": "RHVR8n4CNRCs"
      },
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XUSfnRnOL802",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUSfnRnOL802",
        "outputId": "280326e5-a61f-4115-d28c-008cb10fd4cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1024, 2, 64, 16])"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "g_out = g_model(torch.randn(CONFIG.train_batch_size, CONFIG.z_length).unsqueeze(-1).unsqueeze(-1), \n",
        "                b.unsqueeze(-1).unsqueeze(-1))\n",
        "g_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7Jq_hbf8NWKx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Jq_hbf8NWKx",
        "outputId": "59ebf705-00ec-4809-fa19-644e4828833c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'generator_params': 3290178, 'discriminator_params': 2277892}"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "{'generator_params': count_parameters(g_model),\n",
        " 'discriminator_params': count_parameters(d_model)}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "029bfac3",
      "metadata": {
        "id": "029bfac3"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55064259",
      "metadata": {
        "id": "55064259"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "from torch.utils import data\n",
        "import numpy as np\n",
        "from meta_gan.feature_extraction.MetaFeaturesCollector import MetaFeaturesCollector\n",
        "from meta_gan.feature_extraction.LambdaFeaturesCollector import LambdaFeaturesCollector\n",
        "\n",
        "\n",
        "class LambdaDatasetFolder(data.Dataset):\n",
        "\n",
        "    def __init__(self, path: str, features_size: int, instances_size: int, classes_size: int,\n",
        "                 lambdas: LambdaFeaturesCollector):\n",
        "        self.root = path\n",
        "        self.features = features_size\n",
        "        self.instances = instances_size\n",
        "        self.classes = classes_size\n",
        "        paths = []\n",
        "        for fname in os.listdir(self.root):\n",
        "            path = os.path.join(self.root, fname)\n",
        "            if not os.path.isdir(path):\n",
        "                paths.append(path)\n",
        "        # print(f'paths = {paths}')\n",
        "        from collections import Counter\n",
        "        shapes = []\n",
        "        for i in paths:\n",
        "            loaded_np_data = np.load(i, allow_pickle=True)\n",
        "            shapes.append(loaded_np_data.shape)\n",
        "            if loaded_np_data.shape == (8000, 27):\n",
        "                print(i)\n",
        "                exit(0)\n",
        "            # print(f'loaded_np_data.shape = {loaded_np_data.}')\n",
        "        print(f'shapes = {Counter(shapes)}')\n",
        "        self.data_paths = paths\n",
        "        self.lambda_features = lambdas\n",
        "\n",
        "    def __getitem__(self, index) -> (torch.Tensor, torch.Tensor, torch.Tensor):\n",
        "        data_path = self.data_paths[index]\n",
        "        data_np = np.load(data_path, allow_pickle=True)\n",
        "        dataset_tensor = torch.from_numpy(data_np).float().view((self.classes, self.instances, self.features))\n",
        "        dataset_tensor = dataset_tensor.flatten(0, 1)\n",
        "\n",
        "        lambda_tensor = self.lambda_features.get(data_np)\n",
        "        return dataset_tensor, lambda_tensor\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa3f9827",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa3f9827",
        "outputId": "e4ef046b-e973-4bda-d46d-63085d99f4fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shapes = Counter({(2, 64, 16): 8000})\n",
            "shapes = Counter({(2, 64, 16): 1911})\n"
          ]
        }
      ],
      "source": [
        "lambdaFeaturesCollector = LambdaFeaturesCollector(CONFIG.features, CONFIG.instances)\n",
        "\n",
        "train_dataset = LambdaDatasetFolder('processed_data/processed_16_64_2/', \n",
        "                              CONFIG.features,\n",
        "                              CONFIG.instances,\n",
        "                              CONFIG.classes,\n",
        "                              lambdaFeaturesCollector)\n",
        "\n",
        "test_lambdaFeaturesCollector = LambdaFeaturesCollector(CONFIG.features, CONFIG.instances)\n",
        "\n",
        "test_dataset = LambdaDatasetFolder('processed_data/test/',\n",
        "                                CONFIG.features,\n",
        "                                CONFIG.instances,\n",
        "                                CONFIG.classes,\n",
        "                                test_lambdaFeaturesCollector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ac450de",
      "metadata": {
        "id": "6ac450de"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, \n",
        "                              batch_size=CONFIG.train_batch_size,\n",
        "                              num_workers=CONFIG.num_workers,\n",
        "                              shuffle=True)\n",
        "\n",
        "test_dataloader = DataLoader(test_dataset,\n",
        "                              batch_size=CONFIG.test_batch_size,\n",
        "                              num_workers=CONFIG.num_workers,\n",
        "                              shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5yWvh7bC5fxS",
      "metadata": {
        "id": "5yWvh7bC5fxS"
      },
      "source": [
        "## DataSet With Metas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46Kapld95e2J",
      "metadata": {
        "id": "46Kapld95e2J"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils import data\n",
        "import numpy as np\n",
        "from meta_gan.feature_extraction.MetaFeaturesCollector import MetaFeaturesCollector\n",
        "from meta_gan.feature_extraction.LambdaFeaturesCollector import LambdaFeaturesCollector\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import os\n",
        "\n",
        "class DatasetWithMetaFolder(data.Dataset):\n",
        "\n",
        "    def __init__(self, path: str, features_size: int, instances_size: int, classes_size: int,\n",
        "                 meta: MetaFeaturesCollector, lambdas: LambdaFeaturesCollector, train_meta: bool,\n",
        "                 meta_precalc_path: str, standardscale=False):\n",
        "        self.root = path\n",
        "        self.features = features_size\n",
        "        self.instances = instances_size\n",
        "        self.classes = classes_size\n",
        "        self.meta_precalc_path = meta_precalc_path\n",
        "        self.meta_precalculated = np.load(self.meta_precalc_path, allow_pickle=True)\n",
        "        paths = []\n",
        "        for fname in os.listdir(self.root):\n",
        "            path = os.path.join(self.root, fname)\n",
        "            if not os.path.isdir(path):\n",
        "                paths.append(path)\n",
        "        # print(f'paths = {paths}')\n",
        "        from collections import Counter\n",
        "        shapes = []\n",
        "        for i in paths:\n",
        "            loaded_np_data = np.load(i, allow_pickle=True)\n",
        "            shapes.append(loaded_np_data.shape)\n",
        "            if loaded_np_data.shape == (8000, 27):\n",
        "                print(i)\n",
        "                # exit(0)\n",
        "            # print(f'loaded_np_data.shape = {loaded_np_data.}')\n",
        "        print(f'shapes = {Counter(shapes)}')\n",
        "        self.data_paths = paths\n",
        "        self.meta_features = meta\n",
        "        if train_meta:\n",
        "            self.meta_features.train(self.root, load_from_fs=True)\n",
        "        \n",
        "        self.standardscale = standardscale\n",
        "        self.lambda_features = lambdas\n",
        "        self.data_scaler = StandardScaler()\n",
        "        self.all_data = np.concatenate([np.load(i, allow_pickle=True) for i in self.data_paths])\n",
        "        self.all_data = self.all_data.reshape((-1, self.all_data.shape[-1]))\n",
        "        print(f\"shape = {self.all_data.shape}\")\n",
        "        self.data_scaler.fit(self.all_data)\n",
        "        del self.all_data\n",
        "\n",
        "    def __getitem__(self, index) -> (torch.Tensor, torch.Tensor, torch.Tensor):\n",
        "        data_path = self.data_paths[index]\n",
        "        data_np = np.load(data_path, allow_pickle=True)\n",
        "        dataset_tensor = torch.from_numpy(data_np).float().view((self.classes, self.instances, self.features))\n",
        "        dataset_tensor = dataset_tensor.flatten(0, 1)\n",
        "\n",
        "        # meta_tensor = self.meta_features.get(data_np)\n",
        "        meta_tensor = torch.Tensor(self.meta_precalculated[index])\n",
        "        meta_tensor = meta_tensor.view(self.meta_features.getLength(), 1, 1)\n",
        "        lambda_tensor = self.lambda_features.get(data_np)\n",
        "\n",
        "        if self.standardscale:\n",
        "            dataset_tensor = torch.Tensor(self.data_scaler.transform(dataset_tensor))\n",
        "\n",
        "        return dataset_tensor, meta_tensor, lambda_tensor\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_paths)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FNWMVR5D5oe1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNWMVR5D5oe1",
        "outputId": "09548823-ff28-47e1-ab0b-cc0eae84194a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shapes = Counter({(2, 64, 16): 8000})\n",
            "processed_data/processed_16_64_2/\n",
            "Loaded from file system\n",
            "shape = (1024000, 16)\n",
            "shapes = Counter({(2, 64, 16): 1911})\n",
            "shape = (244608, 16)\n"
          ]
        }
      ],
      "source": [
        "lambdaFeaturesCollector = LambdaFeaturesCollector(CONFIG.features, CONFIG.instances)\n",
        "metaFeaturesCollector = MetaFeaturesCollector(CONFIG.features, CONFIG.instances)\n",
        "train_dataset = DatasetWithMetaFolder('processed_data/processed_16_64_2/', \n",
        "                              CONFIG.features,\n",
        "                              CONFIG.instances,\n",
        "                              CONFIG.classes,\n",
        "                              metaFeaturesCollector,\n",
        "                              lambdaFeaturesCollector,\n",
        "                              True,\n",
        "                              'train_meta_tensors.npy',\n",
        "                              standardscale=CONFIG.standardscaler)\n",
        "\n",
        "test_lambdaFeaturesCollector = LambdaFeaturesCollector(CONFIG.features, CONFIG.instances)\n",
        "\n",
        "test_dataset = DatasetWithMetaFolder('processed_data/test/', \n",
        "                              CONFIG.features,\n",
        "                              CONFIG.instances,\n",
        "                              CONFIG.classes,\n",
        "                              metaFeaturesCollector,\n",
        "                              lambdaFeaturesCollector,\n",
        "                              False,\n",
        "                              'test_meta_tensors.npy',\n",
        "                              standardscale=CONFIG.standardscaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OS930tGJ5tQ1",
      "metadata": {
        "id": "OS930tGJ5tQ1"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, \n",
        "                              batch_size=CONFIG.train_batch_size,\n",
        "                              num_workers=CONFIG.num_workers,\n",
        "                              shuffle=True)\n",
        "\n",
        "test_dataloader = DataLoader(test_dataset,\n",
        "                              batch_size=CONFIG.test_batch_size,\n",
        "                              num_workers=CONFIG.num_workers,\n",
        "                              shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73TfKVoa0jVF",
      "metadata": {
        "id": "73TfKVoa0jVF"
      },
      "source": [
        "## dataset with cached lambdas and norm\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PlWFMvEw0jI4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlWFMvEw0jI4",
        "outputId": "a59fef47-7c5c-43aa-f9d9-d569ba077074"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shapes = Counter({(2, 64, 16): 8000})\n",
            "processed_data/processed_16_64_2/\n",
            "Loaded from file system\n",
            "shape = (1024000, 16)\n",
            "shapes = Counter({(2, 64, 16): 1911})\n",
            "shape = (244608, 16)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils import data\n",
        "import numpy as np\n",
        "from meta_gan.feature_extraction.MetaFeaturesCollector import MetaFeaturesCollector\n",
        "from meta_gan.feature_extraction.LambdaFeaturesCollector import LambdaFeaturesCollector\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import os\n",
        "\n",
        "class DatasetWithMetaFolder(data.Dataset):\n",
        "\n",
        "    def __init__(self, path: str, features_size: int, instances_size: int, classes_size: int,\n",
        "                 meta: MetaFeaturesCollector, lambdas: LambdaFeaturesCollector, train_meta: bool,\n",
        "                 meta_precalc_path: str = None, lambda_precalc_path: str = None, \n",
        "                 standardscale=False, meta_standardscale=False, transpose=False):\n",
        "        self.root = path\n",
        "        self.features = features_size\n",
        "        self.instances = instances_size\n",
        "        self.classes = classes_size\n",
        "        self.metas = meta\n",
        "        self.lambdas = lambdas\n",
        "        self.meta_precalc_path = meta_precalc_path\n",
        "        self.lambda_precalc_path = lambda_precalc_path\n",
        "        if self.meta_precalc_path is not None:\n",
        "            self.meta_precalculated = np.load(self.meta_precalc_path, allow_pickle=True)\n",
        "        if self.lambda_precalc_path is not None:\n",
        "            self.lambda_precalculated = np.load(self.lambda_precalc_path, allow_pickle=True)\n",
        "        self.standardscale = standardscale\n",
        "        self.meta_standardscale = meta_standardscale\n",
        "        self.transpose = transpose\n",
        "        paths = []\n",
        "        for fname in os.listdir(self.root):\n",
        "            path = os.path.join(self.root, fname)\n",
        "            if not os.path.isdir(path):\n",
        "                paths.append(path)\n",
        "        # print(f'paths = {paths}')\n",
        "        from collections import Counter\n",
        "        shapes = []\n",
        "        for i in paths:\n",
        "            loaded_np_data = np.load(i, allow_pickle=True)\n",
        "            shapes.append(loaded_np_data.shape)\n",
        "            if loaded_np_data.shape == (8000, 27):\n",
        "                print(i)\n",
        "                # exit(0)\n",
        "            # print(f'loaded_np_data.shape = {loaded_np_data.}')\n",
        "        print(f'shapes = {Counter(shapes)}')\n",
        "        self.data_paths = paths\n",
        "        self.meta_features = meta\n",
        "        if train_meta:\n",
        "            self.meta_features.train(self.root, load_from_fs=True)\n",
        "        \n",
        "        self.lambda_features = lambdas\n",
        "        # standardscale\n",
        "        if self.standardscale:\n",
        "            self.data_scaler = StandardScaler()\n",
        "            self.all_data = np.concatenate([np.load(i, allow_pickle=True) for i in self.data_paths])\n",
        "            self.all_data = self.all_data.reshape((-1, self.all_data.shape[-1]))\n",
        "            print(f\"shape = {self.all_data.shape}\")\n",
        "            self.data_scaler.fit(self.all_data)\n",
        "            del self.all_data\n",
        "\n",
        "        # meta_standard_scale\n",
        "\n",
        "        if self.meta_standardscale:\n",
        "            self.meta_data_scaler = StandardScaler()\n",
        "            all_meta_data = None\n",
        "            if self.meta_precalc_path is not None:\n",
        "                all_meta_data = self.meta_precalculated\n",
        "            else:\n",
        "                raise NotImplementedError(\":)\")\n",
        "            self.meta_data_scaler.fit(all_meta_data.reshape(-1, self.meta_features.getLength()))\n",
        "\n",
        "    def __getitem__(self, index) -> (torch.Tensor, torch.Tensor, torch.Tensor):\n",
        "        data_path = self.data_paths[index]\n",
        "        data_np = np.load(data_path, allow_pickle=True)\n",
        "        dataset_tensor = torch.from_numpy(data_np).float().view((self.classes, self.instances, self.features))\n",
        "        dataset_tensor = dataset_tensor.flatten(0, 1)\n",
        "\n",
        "        # meta_tensor = self.meta_features.get(data_np)\n",
        "        meta_tensor = torch.Tensor(self.meta_precalculated[index])\n",
        "        meta_tensor = meta_tensor.view(self.meta_features.getLength(), 1, 1)\n",
        "        lambda_tensor = torch.Tensor(self.lambda_precalculated[index])\n",
        "\n",
        "        if self.standardscale:\n",
        "            dataset_tensor = torch.Tensor(self.data_scaler.transform(dataset_tensor))\n",
        "\n",
        "        if self.meta_standardscale:\n",
        "            meta_tensor = torch.Tensor(self.meta_data_scaler.transform(meta_tensor.reshape(-1, self.meta_features.getLength()))).reshape(-1)\n",
        "\n",
        "        total_elems = self.classes * self.instances\n",
        "        dataset_tensor = torch.cat([dataset_tensor, \n",
        "                   (torch.arange(0, total_elems) < total_elems / 2).reshape((total_elems, 1))],\n",
        "                #    (torch.arange(0, total_elems) >= total_elems / 2).reshape((total_elems, 1))], \n",
        "                  dim=1)\n",
        "        if self.transpose:\n",
        "            dataset_tensor = dataset_tensor.T\n",
        "        return dataset_tensor, meta_tensor, lambda_tensor\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_paths)\n",
        "\n",
        "    def precalc(self, pref_name):\n",
        "        from tqdm import tqdm\n",
        "        meta_tensors = []\n",
        "        for i in tqdm(range(self.__len__()), total=self.__len__()):\n",
        "            data_path = self.data_paths[i]\n",
        "            data_np = np.load(data_path, allow_pickle=True)\n",
        "\n",
        "            meta_tensor = self.meta_features.get(data_np)\n",
        "            meta_tensor = meta_tensor.view(self.meta_features.getLength(), 1, 1)\n",
        "            meta_tensors.append(meta_tensor)\n",
        "        \n",
        "        # write meta_tensors to numpy_file\n",
        "        meta_tensors = torch.stack(meta_tensors).numpy()\n",
        "        np.save(f'{pref_name}_meta_tensors.npy', meta_tensors)\n",
        "\n",
        "    def precalc_lambda(self, pref_name):\n",
        "        from tqdm import tqdm\n",
        "        lambda_tensors = []\n",
        "        for i in tqdm(range(self.__len__()), total=self.__len__()):\n",
        "            data_path = self.data_paths[i]\n",
        "            data_np = np.load(data_path, allow_pickle=True)\n",
        "\n",
        "            lambda_tensor = self.lambda_features.get(data_np)\n",
        "            lambda_tensors.append(lambda_tensor)\n",
        "            \n",
        "        # write meta_tensors to numpy_file\n",
        "        lambda_tensors = torch.stack(lambda_tensors).numpy()\n",
        "        print(lambda_tensors.shape)\n",
        "        np.save(f'{pref_name}_lambda_tensors.npy', lambda_tensors)\n",
        "\n",
        "\n",
        "from copy import deepcopy\n",
        "\n",
        "lambdaFeaturesCollector = LambdaFeaturesCollector(CONFIG.features, CONFIG.instances)\n",
        "metaFeaturesCollector = MetaFeaturesCollector(CONFIG.features, CONFIG.instances)\n",
        "train_dataset = DatasetWithMetaFolder('processed_data/processed_16_64_2/', \n",
        "                              CONFIG.features,\n",
        "                              CONFIG.instances,\n",
        "                              CONFIG.classes,\n",
        "                              metaFeaturesCollector,\n",
        "                              lambdaFeaturesCollector,\n",
        "                              True,\n",
        "                              meta_precalc_path='train_meta_tensors.npy',\n",
        "                              lambda_precalc_path='train_lambda_lambda_tensors.npy',\n",
        "                              standardscale=CONFIG.standardscaler,\n",
        "                              meta_standardscale=CONFIG.meta_standardscaler,\n",
        "                              transpose=CONFIG.transpose)\n",
        "\n",
        "test_lambdaFeaturesCollector = LambdaFeaturesCollector(CONFIG.features, CONFIG.instances)\n",
        "\n",
        "test_dataset = DatasetWithMetaFolder('processed_data/test/', \n",
        "                              CONFIG.features,\n",
        "                              CONFIG.instances,\n",
        "                              CONFIG.classes,\n",
        "                              metaFeaturesCollector,\n",
        "                              lambdaFeaturesCollector,\n",
        "                              False,\n",
        "                              meta_precalc_path='test_meta_tensors.npy',\n",
        "                              lambda_precalc_path='test_lambda_lambda_tensors.npy',\n",
        "                              standardscale=CONFIG.standardscaler,\n",
        "                              meta_standardscale=CONFIG.meta_standardscaler,\n",
        "                              transpose=CONFIG.transpose)\n",
        "\n",
        "test_dataset.data_scaler = deepcopy(train_dataset.data_scaler)\n",
        "test_dataset.meta_data_scaler = deepcopy(test_dataset.meta_data_scaler)\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, \n",
        "                              batch_size=CONFIG.train_batch_size,\n",
        "                              num_workers=CONFIG.num_workers,\n",
        "                              shuffle=True)\n",
        "\n",
        "test_dataloader = DataLoader(test_dataset,\n",
        "                              batch_size=CONFIG.test_batch_size,\n",
        "                              num_workers=CONFIG.num_workers,\n",
        "                              shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9Tn5CYRUrM2M",
      "metadata": {
        "id": "9Tn5CYRUrM2M"
      },
      "source": [
        "## dataset with labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6O58gfzGrKoR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6O58gfzGrKoR",
        "outputId": "92adbab1-878b-4f53-e2db-8a0f7cbee323"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shapes = Counter({(2, 64, 16): 8000})\n",
            "processed_data/processed_16_64_2/\n",
            "Loaded from file system\n",
            "shape = (1024000, 16)\n",
            "shapes = Counter({(2, 64, 16): 1911})\n",
            "shape = (244608, 16)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils import data\n",
        "import numpy as np\n",
        "from meta_gan.feature_extraction.MetaFeaturesCollector import MetaFeaturesCollector\n",
        "from meta_gan.feature_extraction.LambdaFeaturesCollector import LambdaFeaturesCollector\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import os\n",
        "\n",
        "class DatasetWithTargets(data.Dataset):\n",
        "\n",
        "    def __init__(self, path: str, features_size: int, instances_size: int, classes_size: int,\n",
        "                 meta: MetaFeaturesCollector, lambdas: LambdaFeaturesCollector, train_meta: bool,\n",
        "                 meta_precalc_path: str = None, lambda_precalc_path: str = None, \n",
        "                 standardscale=False, meta_standardscale=False, transpose=False):\n",
        "        self.root = path\n",
        "        self.features = features_size\n",
        "        self.instances = instances_size\n",
        "        self.classes = classes_size\n",
        "        self.metas = meta\n",
        "        self.lambdas = lambdas\n",
        "        self.meta_precalc_path = meta_precalc_path\n",
        "        self.lambda_precalc_path = lambda_precalc_path\n",
        "        if self.meta_precalc_path is not None:\n",
        "            self.meta_precalculated = np.load(self.meta_precalc_path, allow_pickle=True)\n",
        "        if self.lambda_precalc_path is not None:\n",
        "            self.lambda_precalculated = np.load(self.lambda_precalc_path, allow_pickle=True)\n",
        "        self.standardscale = standardscale\n",
        "        self.meta_standardscale = meta_standardscale\n",
        "        self.transpose = transpose\n",
        "        paths = []\n",
        "        for fname in os.listdir(self.root):\n",
        "            path = os.path.join(self.root, fname)\n",
        "            if not os.path.isdir(path):\n",
        "                paths.append(path)\n",
        "        # print(f'paths = {paths}')\n",
        "        from collections import Counter\n",
        "        shapes = []\n",
        "        for i in paths:\n",
        "            loaded_np_data = np.load(i, allow_pickle=True)\n",
        "            shapes.append(loaded_np_data.shape)\n",
        "            if loaded_np_data.shape == (8000, 27):\n",
        "                print(i)\n",
        "                # exit(0)\n",
        "            # print(f'loaded_np_data.shape = {loaded_np_data.}')\n",
        "        print(f'shapes = {Counter(shapes)}')\n",
        "        self.data_paths = paths\n",
        "        self.meta_features = meta\n",
        "        if train_meta:\n",
        "            self.meta_features.train(self.root, load_from_fs=True)\n",
        "        \n",
        "        self.lambda_features = lambdas\n",
        "        # standardscale\n",
        "        if self.standardscale:\n",
        "            self.data_scaler = StandardScaler()\n",
        "            self.all_data = np.concatenate([np.load(i, allow_pickle=True) for i in self.data_paths])\n",
        "            self.all_data = self.all_data.reshape((-1, self.all_data.shape[-1]))\n",
        "            print(f\"shape = {self.all_data.shape}\")\n",
        "            self.data_scaler.fit(self.all_data)\n",
        "            del self.all_data\n",
        "\n",
        "        # meta_standard_scale\n",
        "\n",
        "        if self.meta_standardscale:\n",
        "            self.meta_data_scaler = StandardScaler()\n",
        "            all_meta_data = None\n",
        "            if self.meta_precalc_path is not None:\n",
        "                all_meta_data = self.meta_precalculated\n",
        "            else:\n",
        "                raise NotImplementedError(\":)\")\n",
        "            self.meta_data_scaler.fit(all_meta_data.reshape(-1, self.meta_features.getLength()))\n",
        "\n",
        "    def __getitem__(self, index) -> (torch.Tensor, torch.Tensor, torch.Tensor):\n",
        "        data_path = self.data_paths[index]\n",
        "        data_np = np.load(data_path, allow_pickle=True)\n",
        "        dataset_tensor = torch.from_numpy(data_np).float().view((self.classes, self.instances, self.features))\n",
        "        dataset_tensor = dataset_tensor.flatten(0, 1)\n",
        "\n",
        "        # meta_tensor = self.meta_features.get(data_np)\n",
        "        meta_tensor = torch.Tensor(self.meta_precalculated[index])\n",
        "        meta_tensor = meta_tensor.view(self.meta_features.getLength(), 1, 1)\n",
        "        lambda_tensor = torch.Tensor(self.lambda_precalculated[index])\n",
        "\n",
        "        if self.standardscale:\n",
        "            dataset_tensor = torch.Tensor(self.data_scaler.transform(dataset_tensor))\n",
        "\n",
        "        if self.meta_standardscale:\n",
        "            meta_tensor = torch.Tensor(self.meta_data_scaler.transform(meta_tensor.reshape(-1, self.meta_features.getLength()))).reshape(-1)\n",
        "\n",
        "        total_elems = self.classes * self.instances\n",
        "        labels = (torch.arange(0, total_elems) < total_elems / 2).reshape(total_elems)\n",
        "                   \n",
        "    \n",
        "        dataset_tensor = torch.cat([dataset_tensor, \n",
        "                   (torch.arange(0, total_elems) < total_elems / 2).reshape((total_elems, 1)), \n",
        "                   (torch.arange(0, total_elems) >= total_elems / 2).reshape((total_elems, 1))], \n",
        "                  dim=1)\n",
        "        \n",
        "        pos_ = dataset_tensor[labels]\n",
        "        neg_ = dataset_tensor[~labels]\n",
        "        \n",
        "        if self.transpose:\n",
        "            dataset_tensor = dataset_tensor.T\n",
        "            pos_ = pos_.T\n",
        "            neg_ = neg_.T\n",
        "        return pos_, neg_, meta_tensor, lambda_tensor\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_paths)\n",
        "\n",
        "    def precalc(self, pref_name):\n",
        "        from tqdm import tqdm\n",
        "        meta_tensors = []\n",
        "        for i in tqdm(range(self.__len__()), total=self.__len__()):\n",
        "            data_path = self.data_paths[i]\n",
        "            data_np = np.load(data_path, allow_pickle=True)\n",
        "\n",
        "            meta_tensor = self.meta_features.get(data_np)\n",
        "            meta_tensor = meta_tensor.view(self.meta_features.getLength(), 1, 1)\n",
        "            meta_tensors.append(meta_tensor)\n",
        "        \n",
        "        # write meta_tensors to numpy_file\n",
        "        meta_tensors = torch.stack(meta_tensors).numpy()\n",
        "        np.save(f'{pref_name}_meta_tensors.npy', meta_tensors)\n",
        "\n",
        "    def precalc_lambda(self, pref_name):\n",
        "        from tqdm import tqdm\n",
        "        lambda_tensors = []\n",
        "        for i in tqdm(range(self.__len__()), total=self.__len__()):\n",
        "            data_path = self.data_paths[i]\n",
        "            data_np = np.load(data_path, allow_pickle=True)\n",
        "\n",
        "            lambda_tensor = self.lambda_features.get(data_np)\n",
        "            lambda_tensors.append(lambda_tensor)\n",
        "            \n",
        "        # write meta_tensors to numpy_file\n",
        "        lambda_tensors = torch.stack(lambda_tensors).numpy()\n",
        "        print(lambda_tensors.shape)\n",
        "        np.save(f'{pref_name}_lambda_tensors.npy', lambda_tensors)\n",
        "\n",
        "\n",
        "from copy import deepcopy\n",
        "\n",
        "lambdaFeaturesCollector = LambdaFeaturesCollector(CONFIG.features, CONFIG.instances)\n",
        "metaFeaturesCollector = MetaFeaturesCollector(CONFIG.features, CONFIG.instances)\n",
        "train_dataset = DatasetWithTargets('processed_data/processed_16_64_2/', \n",
        "                              CONFIG.features,\n",
        "                              CONFIG.instances,\n",
        "                              CONFIG.classes,\n",
        "                              metaFeaturesCollector,\n",
        "                              lambdaFeaturesCollector,\n",
        "                              True,\n",
        "                              meta_precalc_path='train_meta_tensors.npy',\n",
        "                              lambda_precalc_path='train_lambda_lambda_tensors.npy',\n",
        "                              standardscale=CONFIG.standardscaler,\n",
        "                              meta_standardscale=CONFIG.meta_standardscaler,\n",
        "                              transpose=CONFIG.transpose)\n",
        "\n",
        "test_lambdaFeaturesCollector = LambdaFeaturesCollector(CONFIG.features, CONFIG.instances)\n",
        "\n",
        "test_dataset = DatasetWithTargets('processed_data/test/', \n",
        "                              CONFIG.features,\n",
        "                              CONFIG.instances,\n",
        "                              CONFIG.classes,\n",
        "                              metaFeaturesCollector,\n",
        "                              lambdaFeaturesCollector,\n",
        "                              False,\n",
        "                              meta_precalc_path='test_meta_tensors.npy',\n",
        "                              lambda_precalc_path='test_lambda_lambda_tensors.npy',\n",
        "                              standardscale=CONFIG.standardscaler,\n",
        "                              meta_standardscale=CONFIG.meta_standardscaler,\n",
        "                              transpose=CONFIG.transpose)\n",
        "\n",
        "test_dataset.data_scaler = deepcopy(train_dataset.data_scaler)\n",
        "test_dataset.meta_data_scaler = deepcopy(test_dataset.meta_data_scaler)\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, \n",
        "                              batch_size=CONFIG.train_batch_size,\n",
        "                              num_workers=CONFIG.num_workers,\n",
        "                              shuffle=True)\n",
        "\n",
        "test_dataloader = DataLoader(test_dataset,\n",
        "                              batch_size=CONFIG.test_batch_size,\n",
        "                              num_workers=CONFIG.num_workers,\n",
        "                              shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91a7873e",
      "metadata": {
        "id": "91a7873e"
      },
      "source": [
        "## Init Model + Optimizer + Criterion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a309fab3",
      "metadata": {
        "id": "a309fab3"
      },
      "outputs": [],
      "source": [
        "d_model = Discriminator(hidden_size_0=CONFIG.hidden_size_0, \n",
        "                     hidden_size_1=CONFIG.hidden_size_1, \n",
        "                     predlast_hidden_size=CONFIG.predlast_hidden_size, \n",
        "                     meta_size=CONFIG.meta_size,\n",
        "                     out_classes=CONFIG.out_classes)\n",
        "\n",
        "g_model = Generator(CONFIG.features,\n",
        "                    CONFIG.instances,\n",
        "                    CONFIG.classes,\n",
        "                    CONFIG.meta_size,\n",
        "                    CONFIG.z_length)\n",
        "\n",
        "g_model = g_model.apply(weights_init)\n",
        "\n",
        "d_model = d_model.to(CONFIG.device)\n",
        "g_model = g_model.to(CONFIG.device)\n",
        "\n",
        "d_optimizer = torch.optim.Adam(d_model.parameters(), lr=CONFIG.learning_rate)\n",
        "g_optimizer = torch.optim.Adam(g_model.parameters(), lr=CONFIG.learning_rate)\n",
        "# criterion = torch.nn.MSELoss()\n",
        "BCE = torch.nn.BCEWithLogitsLoss()\n",
        "MSE = torch.nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hh-HFL0rQtg8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hh-HFL0rQtg8",
        "outputId": "4da9b378-e7d2-473c-c8fd-171c98b01cfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb==0.12.20\n",
            "  Downloading wandb-0.12.20-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from wandb==0.12.20) (6.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb==0.12.20) (5.9.4)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.18.0-py2.py3-none-any.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m194.8/194.8 KB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from wandb==0.12.20) (67.6.1)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.9/dist-packages (from wandb==0.12.20) (2.3)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb==0.12.20) (2.27.1)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.9/dist-packages (from wandb==0.12.20) (1.16.0)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.9/dist-packages (from wandb==0.12.20) (3.19.6)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.9/dist-packages (from wandb==0.12.20) (8.1.3)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb==0.12.20) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb==0.12.20) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb==0.12.20) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb==0.12.20) (2022.12.7)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=28eabd9800541b97330ae85f499ccf844479e83e0bd269b7aee3b8174712fb6f\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/0a/67/ada2a22079218c75a88361c0782855cc72aebc4d18d0289d05\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, smmap, shortuuid, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.31 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.18.0 setproctitle-1.3.2 shortuuid-1.0.11 smmap-5.0.0 wandb-0.12.20\n"
          ]
        }
      ],
      "source": [
        " !pip install wandb==0.12.20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ce09db4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ce09db4",
        "outputId": "9a09f3cc-da07-4130-f969-544ee5379f01"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-79dbda87eeff>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# init wandb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcount_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wandb'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# init wandb\n",
        "\n",
        "import wandb\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "cfg = dict(CONFIG.__dict__)\n",
        "cfg.pop('__module__')\n",
        "cfg.pop('__dict__')\n",
        "cfg.pop('__weakref__')\n",
        "cfg.pop('__doc__')\n",
        "cfg['generator_parameteres_num'] = count_parameters(g_model)\n",
        "cfg['discriminator_parameters_num'] = count_parameters(d_model)\n",
        "\n",
        "print(cfg)\n",
        "\n",
        "run = wandb.init(project=\"diploma1234\", config=cfg, id='gan', notes='first gan attempt, discriminator is deepmodelV3, generator like in LM-DCGAN, but instead of mse for probs -- BCEWithLogitsLoss')\n",
        "\n",
        "run.watch(g_model)\n",
        "run.watch(d_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5fbadb7",
      "metadata": {
        "id": "d5fbadb7"
      },
      "source": [
        "## train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcbb2b43",
      "metadata": {
        "id": "fcbb2b43"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bvw9r1chXT4B",
      "metadata": {
        "id": "bvw9r1chXT4B"
      },
      "outputs": [],
      "source": [
        "def getMeta(data_in: torch.Tensor):\n",
        "    meta_list = []\n",
        "    for data in data_in:\n",
        "        meta_list.append(train_dataset.metas.getShort(data.cpu().detach().numpy()))\n",
        "    result = torch.stack(meta_list)\n",
        "    return result.view((result.size(0), result.size(1), 1, 1)).to(CONFIG.device)\n",
        "\n",
        "def getLambda(self, data_in: torch.Tensor):\n",
        "    lamba_list = []\n",
        "    for data in data_in:\n",
        "        lamba_list.append(train_dataset.lambdas.get(data.cpu().detach().numpy()))\n",
        "    result = torch.stack(lamba_list)\n",
        "    return result.to(CONFIG.device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aO6sxrX2iUPR",
      "metadata": {
        "id": "aO6sxrX2iUPR"
      },
      "outputs": [],
      "source": [
        "def transform_flatten_and_cat(dataset_tensor):\n",
        "    total_elems = CONFIG.instances * CONFIG.classes\n",
        "    dataset_tensor = fake_data.flatten(1, 2)\n",
        "    result = torch.cat([dataset_tensor, \n",
        "                   (torch.arange(0, total_elems) < total_elems / 2).reshape((total_elems, 1))],\n",
        "          dim=1)\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c89f0669",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 796,
          "referenced_widgets": [
            "ca8f4b47367d402db3460dd82753a79f",
            "2b88aefaf8c84bd4bcbe328343d80d78",
            "2b5592a55c58495189f7da3a8baed640",
            "f6ac86dca1c84f4bbf2ac09a93492115",
            "19dc22e42e0c41daac7dd343d1e8184e",
            "c204a96a6f0a481584624d02562b0cca",
            "a371e124c3c540448322670b561d77ac",
            "95612f0d5543466bba0c201e423f9e71",
            "5397b429160d4a158c24e67409b19e29",
            "063e6e17bf3f4b2d825aaba7d165f5b9",
            "53b3b43ab5e343c78e51c192a03cd529"
          ]
        },
        "id": "c89f0669",
        "outputId": "f4ef165c-c910-4e2d-d233-b064df1cc470"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca8f4b47367d402db3460dd82753a79f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train Epoch 0:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-cf5e338f7a41>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mfake_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsqueezed_meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mfake_data_metas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetMeta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mfake_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mfake_lambdas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-64-069babf20129>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# (batch_size * N, M, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequiv_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;31m# (batch_size * N, M, hidden_size_0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/deepsets/deepsetlayers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X, mask)\u001b[0m\n\u001b[1;32m    136\u001b[0m            \u001b[0mout_features\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \"\"\"\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
          ]
        }
      ],
      "source": [
        "for epoch in range(CONFIG.num_epochs):\n",
        "    # train loop\n",
        "    train_g_epoch_loss = 0\n",
        "    train_d_epoch_loss = 0\n",
        "    for (ind, (X, meta, y)) in tqdm(enumerate(train_dataloader), total=len(train_dataloader), desc=f\"Train Epoch {epoch}\"):\n",
        "        X = X.to(CONFIG.device)\n",
        "        meta = meta.to(CONFIG.device)\n",
        "        unsqueezed_meta = meta.unsqueeze(-1).unsqueeze(-1)\n",
        "        y = y.to(CONFIG.device)\n",
        "        noise = torch.randn(CONFIG.train_batch_size, CONFIG.z_length) \\\n",
        "            .unsqueeze(-1).unsqueeze(-1).to(CONFIG.device)\n",
        "        zeros = torch.zeros([CONFIG.train_batch_size, 1], dtype=torch.float32, \n",
        "                            device=CONFIG.device)\n",
        "        ones = torch.ones([CONFIG.train_batch_size, 1], dtype=torch.float32, \n",
        "                            device=CONFIG.device)\n",
        "        \n",
        "        # Get D on real\n",
        "        real_outputs = d_model(X, meta)\n",
        "        d_real_labels_loss = MSE(real_outputs[:, 1:], y)\n",
        "        d_real_rf_loss = MSE(real_outputs[:, :1], zeros) # :TODO: CHANGE TO BCE\n",
        "        d_real_loss = d_real_labels_loss + 0.7 * d_real_rf_loss\n",
        "\n",
        "        # Get D on fake\n",
        "        fake_data = g_model(noise, unsqueezed_meta)\n",
        "        fake_data_metas = getMeta(fake_data)\n",
        "        fake_outputs = d_model(fake_data, meta)\n",
        "        fake_lambdas = getLambda(fake_data)\n",
        "\n",
        "        smoothing_coef = torch.exp(-torch.square(torch.norm(unsqueezed_meta - fake_data_metas)))\n",
        "        d_fake_labels_loss = MSE(fake_outputs[:, 1:], fake_lambdas)\n",
        "        d_fake_rf_loss = MSE(fake_outputs[:, :1], ones) # :TODO: CHANGE TO BCE\n",
        "        d_fake_loss = 0.7 * d_fake_rf_loss + smoothing_coef * d_fake_labels_loss\n",
        "\n",
        "        # Train D\n",
        "        d_loss = d_real_loss + 0.8 * d_fake_loss\n",
        "        g_model.zero_grad()\n",
        "        d_model.zero_grad()\n",
        "        d_loss.backward()\n",
        "        d_optimizer.step()\n",
        "\n",
        "        train_d_epoch_loss += d_loss\n",
        "\n",
        "        # Get D on fake\n",
        "        noise = torch.randn(CONFIG.train_batch_size, CONFIG.z_length) \\\n",
        "            .unsqueeze(-1).unsqueeze(-1).to(CONFIG.device)\n",
        "        fake_data = g_model(noise, unsqueezed_meta)\n",
        "        fake_outputs = d_model(fake_data, meta)\n",
        "        g_fake_rf_loss = MSE(fake_outputs[:, :1], zeros) # :TODO: CHANGE TO BCE\n",
        "        fake_metas = getMeta(fake_data)\n",
        "        g_fake_meta_loss = MSE(fake_metas, unsqueezed_meta)\n",
        "        g_loss = 0.7 * g_fake_rf_loss + g_fake_meta_loss\n",
        "\n",
        "        # Train G\n",
        "        g_model.zero_grad()\n",
        "        d_model.zero_grad()\n",
        "        g_loss.backward()\n",
        "        g_optimizer.step()\n",
        "\n",
        "        train_g_epoch_loss += g_loss.item()\n",
        "\n",
        "    train_g_epoch_loss = train_g_epoch_loss / len(train_dataloader)\n",
        "    train_d_epoch_loss = train_d_epoch_loss / len(train_dataloader)\n",
        "\n",
        "    # test loop\n",
        "    test_epoch_loss = 0\n",
        "    test_squared_error = 0\n",
        "    test_total_elems = 0\n",
        "    for (ind, (X, meta, y)) in tqdm(enumerate(test_dataloader), total=len(test_dataloader), desc=f\"Test Epoch {epoch}\"):\n",
        "        X = X.to(CONFIG.device)\n",
        "        meta = meta.to(CONFIG.device)\n",
        "        y = y.to(CONFIG.device)\n",
        "\n",
        "        y_pred = d_model(X, meta)\n",
        "        loss = MSE(y_pred, y)\n",
        "\n",
        "        test_epoch_loss += loss.item()\n",
        "\n",
        "        # y_pred_ = torch.sigmoid(y_pred)\n",
        "        y_pred_ = y_pred[:, 1:]\n",
        "\n",
        "        # update test squared error without mean\n",
        "        test_squared_error += torch.sum((y_pred_ - y) ** 2).item()\n",
        "        test_total_elems += y_pred.shape[0] * y_pred.shape[1]\n",
        "\n",
        "\n",
        "    test_epoch_loss = test_epoch_loss / len(test_dataloader)\n",
        "    test_mse = test_squared_error / test_total_elems\n",
        "    wandb.log({\"train_g_loss\": train_g_epoch_loss,\n",
        "               \"train_d_loss\": train_d_epoch_loss,\n",
        "               \"test_loss\": test_epoch_loss,\n",
        "               \"test_mse\": test_mse})\n",
        "\n",
        "\n",
        "\n",
        "    print(f'Epoch {epoch} train generator loss: {train_g_epoch_loss}')\n",
        "    print(f'Epoch {epoch} train discriminator loss: {train_d_epoch_loss}')\n",
        "    print(f'Epoch {epoch} test loss: {test_epoch_loss}')\n",
        "    print(f'Epoch {epoch} test mse: {test_mse}')\n",
        "    print()\n",
        "\n",
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "APtjj-ITzO72",
        "029bfac3",
        "5yWvh7bC5fxS",
        "9Tn5CYRUrM2M"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "063e6e17bf3f4b2d825aaba7d165f5b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19dc22e42e0c41daac7dd343d1e8184e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b5592a55c58495189f7da3a8baed640": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95612f0d5543466bba0c201e423f9e71",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5397b429160d4a158c24e67409b19e29",
            "value": 0
          }
        },
        "2b88aefaf8c84bd4bcbe328343d80d78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c204a96a6f0a481584624d02562b0cca",
            "placeholder": "",
            "style": "IPY_MODEL_a371e124c3c540448322670b561d77ac",
            "value": "Train Epoch 0:   0%"
          }
        },
        "5397b429160d4a158c24e67409b19e29": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "53b3b43ab5e343c78e51c192a03cd529": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95612f0d5543466bba0c201e423f9e71": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a371e124c3c540448322670b561d77ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c204a96a6f0a481584624d02562b0cca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca8f4b47367d402db3460dd82753a79f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b88aefaf8c84bd4bcbe328343d80d78",
              "IPY_MODEL_2b5592a55c58495189f7da3a8baed640",
              "IPY_MODEL_f6ac86dca1c84f4bbf2ac09a93492115"
            ],
            "layout": "IPY_MODEL_19dc22e42e0c41daac7dd343d1e8184e"
          }
        },
        "f6ac86dca1c84f4bbf2ac09a93492115": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_063e6e17bf3f4b2d825aaba7d165f5b9",
            "placeholder": "",
            "style": "IPY_MODEL_53b3b43ab5e343c78e51c192a03cd529",
            "value": " 0/8 [03:01&lt;?, ?it/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
